from collections import namedtuple

import numpy as np

import tensorflow as tf

import util

tf.flags.DEFINE_string(
    "train_data_pattern",
    "/tmp/mnist/data/train.csv",
    "Input file path pattern used for training.")

tf.flags.DEFINE_string(
    "eval_data_pattern",
    "/tmp/mnist/data/test.csv",
    "Input file path pattern used for eval.")

tf.flags.DEFINE_string(
    "test_data_pattern",
    "/tmp/mnist/data/train.csv",
    "Input file path pattern used for testing.")

tf.flags.DEFINE_integer("batch_size", 100, "Batch size.")

tf.flags.DEFINE_integer("num_train_steps", 1000,
                        "The number of steps to run training for.")

tf.flags.DEFINE_float("learning_rate", 1e-2, "Learning rate.")

FLAGS = tf.flags.FLAGS


def get_feature_columns():
    features = tf.contrib.layers.real_valued_column(
        'features', dimension=784, default_value=0.0)
    return [features]


def make_input_fn(file_name, num_epochs):
    def _input_fn():
        columns = util.read_tensors_from_csv(file_name, num_columns=785, batch_size=FLAGS.batch_size,
                                             num_epochs=num_epochs)
        targets = tf.cast(columns.pop('0'), tf.int32)

        normalized_features = []
        for column in columns:
            normalized_features.append(columns[column] / 255.0)
        features = {'features': tf.stack(normalized_features, axis=1)}

        return features, targets

    return _input_fn


def get_estimator(model_dir):
    estimator = tf.contrib.learn.DNNClassifier(
        feature_columns=get_feature_columns(),
        hidden_units=[300, 200, 100],
        n_classes=10,
        optimizer=tf.train.AdamOptimizer(FLAGS.learning_rate),
        model_dir=model_dir)
    return estimator


def train(model_dir):
    print('Training ...')

    estimator = get_estimator(model_dir)
    estimator.fit(input_fn=make_input_fn(FLAGS.train_data_pattern, None), steps=5000)

    print('Done.')


def eval(model_dir):
    print('Evaluating ...')

    estimator = get_estimator(model_dir)
    scores = estimator.evaluate(input_fn=make_input_fn(FLAGS.eval_data_pattern, 1), steps=None)
    print(scores)

    print('Done.')

Dataset = namedtuple('Dataset', ['data', 'target'])

def predict(model_dir):
    print('Predict ...')

    estimator = get_estimator(model_dir)

    instances = np.array(
        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 77, 254, 107, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         19, 227, 254, 254, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 254, 254, 165,
         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 203, 254, 254, 73, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 254, 254, 250, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 134, 254, 254, 180, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 196, 254, 248, 48, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 58, 254, 254,
         237, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 111, 254, 254, 132, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 163, 254, 238, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 60, 252, 254, 223, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 79, 254, 254, 154, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 163,
         254, 238, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 252, 254, 210, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 86, 254, 254, 131, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 105, 254, 234, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 175, 254, 204, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5,
         211, 254, 196, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 158, 254, 160, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 26, 157, 107, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]) / 255.0

    data = np.zeros((1, 784), dtype=np.float)
    x = {'features' : data}

    y = estimator.predict(x=data, input_fn=None, batch_size=1)
    print(y)

    print('Done.')

def main():
    model_dir = '/tmp/mnist/model'

    # train(model_dir)
    eval(model_dir)
    # predict(model_dir)


if __name__ == "__main__":
    main()
